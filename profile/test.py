from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
import concurrent.futures
import json
import time

# ===== Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ØªØµÙØ­ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ =====
def create_driver():
    chrome_options = Options()
    chrome_options.add_argument('--headless')

    # ğŸš« Ù…Ù†Ø¹ Ø§Ù„ØµÙˆØ± Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„ØªØµÙØ­
    prefs = {"profile.managed_default_content_settings.images": 2}
    chrome_options.add_experimental_option("prefs", prefs)

    return webdriver.Chrome(service=Service(), options=chrome_options)

# ===== Ø¬Ù…Ø¹ ÙƒÙ„ Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø£Ù†Ù…ÙŠØ§Øª Ù…Ù† Ø§Ù„Ù…ÙˆØ³Ù… =====
def collect_anime_links(start_url):
    driver = create_driver()
    anime_links = []
    page_number = 1

    driver.get(start_url)
    time.sleep(2)

    while True:
        print(f"ğŸ“„ Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙØ­Ø© Ø±Ù‚Ù… {page_number}...")

        divs = driver.find_elements(By.XPATH, '/html/body/div[5]/div//div[contains(@class, "anime-card-container")]')
        for div in divs:
            try:
                link = div.find_element(By.XPATH, './/h3/a').get_attribute("href").strip()
                if link not in anime_links:
                    anime_links.append(link)
            except:
                continue

        try:
            next_button = driver.find_element(By.XPATH, '//ul[@class="pagination"]//a[span[text()="Â»"]]')
            driver.execute_script("arguments[0].click();", next_button)
            time.sleep(2)
            page_number += 1
        except:
            print("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙØ­Ø© ØªØ§Ù„ÙŠØ©.")
            break

    driver.quit()
    return anime_links

# ===== Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙˆÙ„ Ø­Ù„Ù‚Ø© Ù…Ù† Ø±Ø§Ø¨Ø· Ø£Ù†Ù…ÙŠ ÙˆØ§Ø­Ø¯ =====
def extract_first_episode(anime_url):
    try:
        driver = create_driver()
        driver.get(anime_url)
        time.sleep(1)

        first_ep = driver.find_element(By.XPATH, '//*[@id="DivEpisodesList"]/div/div/div/div/a')
        link = first_ep.get_attribute("href").strip()
        print(f"âœ… {link}")
        driver.quit()
        return link

    except Exception as e:
        print(f"âš ï¸ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ {anime_url}: {e}")
        return None

# ===== Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ =====
if __name__ == "__main__":
    start_url = "https://4t.dvhnar.shop/anime-season/%d8%b5%d9%8a%d9%81-2025/"

    print("ğŸš€ Ø¬Ø§Ø±ÙŠ Ø¬Ù…Ø¹ Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø£Ù†Ù…ÙŠØ§Øª...")
    anime_links = collect_anime_links(start_url)
    print(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(anime_links)} Ø£Ù†Ù…ÙŠ.\n")

    print("ğŸ§µ Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙˆÙ„ Ø­Ù„Ù‚Ø© Ù…Ù† ÙƒÙ„ Ø£Ù†Ù…ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù€ Threads...")

    first_episode_links = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:
        results = list(executor.map(extract_first_episode, anime_links))

    # ØªØµÙÙŠØ© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ø§Ø¬Ø­Ø© ÙÙ‚Ø·
    first_episode_links = [r for r in results if r]

    # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    with open("first_episodes_only.json", "w", encoding="utf-8") as f:
        json.dump(first_episode_links, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“ ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙˆÙ„ Ø­Ù„Ù‚Ø© Ù…Ù† {len(first_episode_links)} Ø£Ù†Ù…ÙŠ ÙˆØ­ÙØ¸Ù‡Ø§ ÙÙŠ first_episodes_only.json")
